{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Controllable generation of Chest X-rays\nIn this notebook, we use the trained GAN model.","metadata":{}},{"cell_type":"code","source":"import os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nimport random\nimport numpy as np\nimport tensorflow as tf\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport ipywidgets as widgets\nfrom functools import partial","metadata":{"id":"a953a2d7","papermill":{"duration":5.69704,"end_time":"2022-07-10T15:30:57.024785","exception":false,"start_time":"2022-07-10T15:30:51.327745","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-07-12T12:47:23.608300Z","iopub.execute_input":"2022-07-12T12:47:23.609223Z","iopub.status.idle":"2022-07-12T12:47:26.184970Z","shell.execute_reply.started":"2022-07-12T12:47:23.609093Z","shell.execute_reply":"2022-07-12T12:47:26.183745Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"seed = 2022\nrandom.seed(seed)\nnp.random.seed(seed)\ntf.random.set_seed(seed)","metadata":{"id":"13e5dedd","papermill":{"duration":0.018666,"end_time":"2022-07-10T15:30:57.052582","exception":false,"start_time":"2022-07-10T15:30:57.033916","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-07-12T12:47:26.186239Z","iopub.execute_input":"2022-07-12T12:47:26.187170Z","iopub.status.idle":"2022-07-12T12:47:26.195053Z","shell.execute_reply.started":"2022-07-12T12:47:26.187116Z","shell.execute_reply":"2022-07-12T12:47:26.193850Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"labels_target = ['Cardiomegaly', 'Infiltration', 'Effusion', 'Male', 'AP']\nlabels_target_ = ['No Cardiomegaly', 'No Infiltration', 'No Effusion', 'Female', 'PA']","metadata":{"id":"f87fc967","papermill":{"duration":0.043776,"end_time":"2022-07-10T15:30:57.204287","exception":false,"start_time":"2022-07-10T15:30:57.160511","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-07-12T12:47:26.197011Z","iopub.execute_input":"2022-07-12T12:47:26.197825Z","iopub.status.idle":"2022-07-12T12:47:26.215256Z","shell.execute_reply.started":"2022-07-12T12:47:26.197751Z","shell.execute_reply":"2022-07-12T12:47:26.213858Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Loading the trained models","metadata":{}},{"cell_type":"markdown","source":"At the end of training, we saved the weights of both generator and dicriminator networks. We can load the weights and evaluate the model. In general, after training is over, we only need to keep the generator. In this case, however, the trained discriminator could be repurposed as a classifier.","metadata":{}},{"cell_type":"code","source":"class chestGAN(tf.keras.Model):\n    \n    def __init__(self, discriminator, generator, latent_dim=512, num_labels=0):\n        \n        super(chestGAN, self).__init__()\n        \n        self.discriminator = discriminator\n        self.generator = generator\n        self.latent_dim = latent_dim\n        self.num_labels = num_labels\n        self.gen_loss_tracker = tf.keras.metrics.Mean(name=\"generator_loss\")\n        self.disc_loss_tracker = tf.keras.metrics.Mean(name=\"discriminator_loss\")\n        self.clf_loss_tracker = tf.keras.metrics.Mean(name='classifier_loss\"')\n        self.ssim_tracker = tf.keras.metrics.Mean(name=\"ssim\")\n        \n        self.config = {\n            'lambda_gp': 0,\n            'lambda_drift': 0,\n            'lambda_clf': 0,\n            'd_steps': 1,\n        }\n        \n\n    @property\n    def metrics(self):\n        \n        if self.config['lambda_clf'] > 0:\n            return [self.gen_loss_tracker, self.disc_loss_tracker, self.clf_loss_tracker, self.ssim_tracker]\n        \n        return [self.gen_loss_tracker, self.disc_loss_tracker, self.ssim_tracker]\n    \n        \n    def compile(self, d_optimizer, g_optimizer, loss_fn, clf_loss_fn=None, mode='dcgan'):\n        \n        super(chestGAN, self).compile()\n        \n        self.d_optimizer = d_optimizer\n        self.g_optimizer = g_optimizer\n        self.loss_fn = loss_fn\n        self.clf_loss_fn = clf_loss_fn\n        self.mode = mode        \n            \n        if self.mode.find('wgan') >= 0:\n            assert self.loss_fn.name == \"wasserstein\", \"Please compile with the Wassertein Loss!\"\n            self.config['d_steps'] = 5\n            self.config['lambda_drift'] = 1e-3\n            if self.mode.find('gp') >= 0:\n                self.config['lambda_gp'] = 10\n        else:\n            assert self.loss_fn.name != \"wasserstein\", \"Please compile with a different adversarial loss!\"\n\n        if self.mode.find('acgan') < 0:\n            assert not self.num_labels, 'mode and num_labels are incompatible'\n        else:\n            assert self.num_labels, 'mode and num_labels are incompatible'\n            self.config['lambda_clf'] = 10\n                \n        print('Training configuration:', self.config)\n       \n    \n    def get_labels(self, predictions, real=True):\n        if self.loss_fn.name == \"wasserstein\":\n            if real:\n                labels = -tf.ones_like(predictions)\n            else:\n                labels = tf.ones_like(predictions)\n        else:\n            if real:\n                labels = tf.ones_like(predictions)\n            else:\n                labels = tf.zeros_like(predictions)\n        return labels\n\n\n    def train_step(self, data):\n        \n        lambda_gp = self.config['lambda_gp']\n        lambda_drift = self.config['lambda_drift']\n        lambda_clf = self.config['lambda_clf'] \n        d_steps = self.config['d_steps']    \n        \n        real_images, target_labels = data\n        \n        prompt = tf.expand_dims(tf.expand_dims(tf.cast(target_labels, tf.float32), axis=1), axis=2)\n        \n        batch_size = tf.shape(real_images)[0]\n        \n        # Train discriminator\n        \n        for _ in range(d_steps):\n            \n            z = tf.random.normal(shape=(batch_size, 1, 1, self.latent_dim))\n            gen_in = tf.concat([z, prompt], axis=-1) if lambda_clf > 0 else z\n            generated_images = self.generator(gen_in)\n\n            with tf.GradientTape() as tape:\n\n                predictions_real = self.discriminator(real_images)\n                predictions_gen = self.discriminator(generated_images)\n\n                labels_real = self.get_labels(predictions_real[:, 0])\n                labels_gen = self.get_labels(predictions_gen[:, 0], False)\n\n                d_loss_real = self.loss_fn(labels_real, predictions_real[:, 0])\n                d_loss_gen = self.loss_fn(labels_gen, predictions_gen[:, 0])\n                \n                d_loss = d_loss_real + d_loss_gen\n                \n                if lambda_gp > 0:\n\n                    epsilon = tf.random.uniform([batch_size, 1, 1, 1], 0.0, 1.0)\n                    interpolates = (1-epsilon)* real_images + epsilon * generated_images\n\n                    with tf.GradientTape() as gp_tape:\n\n                        gp_tape.watch(interpolates)\n                        predictions = self.discriminator(interpolates)[:, 0]\n\n                    grads_gp = gp_tape.gradient(predictions, [interpolates])[0]\n\n                    norm = tf.sqrt(tf.reduce_sum(tf.square(grads_gp), axis=[1, 2, 3]))\n                    gradient_penalty = tf.reduce_mean((norm - 1.0) ** 2)   \n\n                    d_loss += lambda_gp * gradient_penalty \n                \n                if lambda_drift > 0:\n                    \n                    drift_penalty = tf.reduce_mean(predictions_real[:, 0] ** 2)\n                    d_loss += lambda_drift * drift_penalty \n                    \n                if lambda_clf > 0:\n                    \n                    clf_loss_disc = self.clf_loss_fn(target_labels, predictions_real[:, 1:]) \\\n                                    + self.clf_loss_fn(target_labels, predictions_gen[:, 1:])\n                    d_loss += lambda_clf * clf_loss_disc\n\n\n            grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n            self.d_optimizer.apply_gradients(\n                zip(grads, self.discriminator.trainable_weights)\n            )\n            \n            self.disc_loss_tracker.update_state(d_loss)\n            if lambda_clf > 0:\n                self.clf_loss_tracker.update_state(clf_loss_disc)\n        \n        # Train generator\n\n        z = tf.random.normal(shape=(batch_size, 1, 1, self.latent_dim))\n        gen_in = tf.concat([z, prompt], axis=-1) if lambda_clf > 0 else z\n\n        with tf.GradientTape() as tape:\n            \n            fake_images = self.generator(gen_in)\n            predictions = self.discriminator(fake_images)\n            fake_labels = self.get_labels(predictions[:, 0])\n            g_loss = self.loss_fn(fake_labels, predictions[:, 0])\n            \n            if lambda_clf > 0:\n                clf_loss_gen = self.clf_loss_fn(target_labels, predictions[:, 1:])\n                g_loss += lambda_clf * clf_loss_gen\n                \n        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n        self.g_optimizer.apply_gradients(\n            zip(grads, self.generator.trainable_weights)\n        )\n        \n        self.gen_loss_tracker.update_state(g_loss)\n        if lambda_clf > 0:\n            self.clf_loss_tracker.update_state(clf_loss_gen)\n        \n        # Compute Structural Similarity Index between real and fake images\n        ssim = tf.reduce_mean(tf.image.ssim((real_images + 1) / 2, (fake_images + 1) / 2, 1), axis=0)            \n        self.ssim_tracker.update_state(ssim)\n\n        if lambda_clf > 0:\n            return {\n                \"g_loss\": self.gen_loss_tracker.result(),\n                \"d_loss\": self.disc_loss_tracker.result(),\n                \"clf_loss\": self.clf_loss_tracker.result(),\n                \"ssim\": self.ssim_tracker.result()\n            }\n        \n        return {\n            \"g_loss\": self.gen_loss_tracker.result(),\n            \"d_loss\": self.disc_loss_tracker.result(),\n            \"ssim\": self.ssim_tracker.result()\n        }\n    \n    def show_fake(self, path='', num_images=4, label=None, z=[]):\n        \n        if not label:\n            label = self.num_labels * [0]  # Healthy female - PA view\n        elif self.num_labels:\n            assert len(label) == self.num_labels\n            \n        plt.figure(figsize=(num_images*4, 4), facecolor='k')\n        plt.axis('off')\n        \n        prompt = tf.reshape(tf.cast(label, tf.float32), (1, -1))\n        prompt = tf.expand_dims(tf.expand_dims(prompt, axis=1), axis=2)\n        prompt = tf.tile(prompt, [num_images, 1, 1 ,1])\n        \n        if len(z) == 0:\n            z = tf.random.normal(shape=(num_images, 1, 1, self.latent_dim))\n        gen_in = tf.concat([z, prompt], axis=-1) if self.num_labels else z\n        fake_images = self.generator(gen_in)\n        fake_images = (fake_images + 1) / 2\n        fake_images = tf.concat([fake_images[i,:,:,0] for i in range(num_images)], axis=1)\n        plt.imshow(fake_images, cmap='gray')\n        plt.savefig(path)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T12:47:26.218491Z","iopub.execute_input":"2022-07-12T12:47:26.219114Z","iopub.status.idle":"2022-07-12T12:47:26.600511Z","shell.execute_reply.started":"2022-07-12T12:47:26.219076Z","shell.execute_reply":"2022-07-12T12:47:26.597709Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"num_labels = len(labels_target)","metadata":{"id":"679ca47f","papermill":{"duration":0.021219,"end_time":"2022-07-10T15:31:05.250256","exception":false,"start_time":"2022-07-10T15:31:05.229037","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-07-12T12:47:26.603119Z","iopub.execute_input":"2022-07-12T12:47:26.603556Z","iopub.status.idle":"2022-07-12T12:47:26.611077Z","shell.execute_reply.started":"2022-07-12T12:47:26.603519Z","shell.execute_reply":"2022-07-12T12:47:26.609157Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"discriminator = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(16, 3, 2, padding='same', activation=tf.keras.layers.LeakyReLU(0.2), input_shape= (64, 64, 1)),\n    tf.keras.layers.LayerNormalization(axis=[1,2,3]),\n    tf.keras.layers.Conv2D(32, 3, 2, padding='same', activation=tf.keras.layers.LeakyReLU(0.2)),\n    tf.keras.layers.LayerNormalization(axis=[1,2,3]),\n    tf.keras.layers.Conv2D(64, 3, 2, padding='same', activation=tf.keras.layers.LeakyReLU(0.2)),\n    tf.keras.layers.LayerNormalization(axis=[1,2,3]),\n    tf.keras.layers.Conv2D(128, 3, 2, padding='same', activation=tf.keras.layers.LeakyReLU(0.2)),\n    tf.keras.layers.LayerNormalization(axis=[1,2,3]),\n    tf.keras.layers.Conv2D(256, 3, 2, padding='same', activation=tf.keras.layers.LeakyReLU(0.2)),\n    tf.keras.layers.LayerNormalization(axis=[1,2,3]),\n    tf.keras.layers.Conv2D(512, 3, 2, padding='same', activation=tf.keras.layers.LeakyReLU(0.2)),\n    tf.keras.layers.LayerNormalization(axis=[1,2,3]),\n    tf.keras.layers.Conv2D(1+num_labels, 3, 2, padding='same', activation=tf.keras.layers.LeakyReLU(0.2)),\n    tf.keras.layers.GlobalAveragePooling2D()\n])","metadata":{"id":"ff6a5048","papermill":{"duration":0.305305,"end_time":"2022-07-10T15:31:05.563661","exception":false,"start_time":"2022-07-10T15:31:05.258356","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-07-12T12:47:26.613790Z","iopub.execute_input":"2022-07-12T12:47:26.614835Z","iopub.status.idle":"2022-07-12T12:47:27.257448Z","shell.execute_reply.started":"2022-07-12T12:47:26.614737Z","shell.execute_reply":"2022-07-12T12:47:27.256383Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"generator = tf.keras.Sequential([\n    tf.keras.layers.Conv2DTranspose(512, 3, 2, padding='same', activation='relu', input_shape= (1, 1, 512+num_labels)),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2DTranspose(256, 3, 2, padding='same', activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2DTranspose(128, 3, 2, padding='same', activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2DTranspose(64, 3, 2, padding='same', activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2DTranspose(32, 3, 2, padding='same', activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Conv2DTranspose(1, 3, 2, padding='same', activation='tanh'),\n])","metadata":{"id":"3b6df96f","papermill":{"duration":0.169702,"end_time":"2022-07-10T15:31:05.741345","exception":false,"start_time":"2022-07-10T15:31:05.571643","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-07-12T12:47:27.259292Z","iopub.execute_input":"2022-07-12T12:47:27.259850Z","iopub.status.idle":"2022-07-12T12:47:27.520457Z","shell.execute_reply.started":"2022-07-12T12:47:27.259816Z","shell.execute_reply":"2022-07-12T12:47:27.519185Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"chest_gan = chestGAN(\n    discriminator=discriminator, generator=generator, num_labels=num_labels\n)","metadata":{"id":"17e1fcdb","papermill":{"duration":0.038511,"end_time":"2022-07-10T15:31:05.788497","exception":false,"start_time":"2022-07-10T15:31:05.749986","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-07-12T12:47:27.523169Z","iopub.execute_input":"2022-07-12T12:47:27.523592Z","iopub.status.idle":"2022-07-12T12:47:27.562989Z","shell.execute_reply.started":"2022-07-12T12:47:27.523556Z","shell.execute_reply":"2022-07-12T12:47:27.561816Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"chest_gan.generator.load_weights(\"../input/train-gan-chest-xrays-64/generator.h5\")\nchest_gan.discriminator.load_weights(\"../input/train-gan-chest-xrays-64/discriminator.h5\")","metadata":{"id":"8ba08051","papermill":{"duration":1.235216,"end_time":"2022-07-10T16:31:32.082420","exception":false,"start_time":"2022-07-10T16:31:30.847204","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-07-12T12:47:27.564789Z","iopub.execute_input":"2022-07-12T12:47:27.565665Z","iopub.status.idle":"2022-07-12T12:47:28.359480Z","shell.execute_reply.started":"2022-07-12T12:47:27.565627Z","shell.execute_reply":"2022-07-12T12:47:28.358112Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Evaluating the GAN","metadata":{}},{"cell_type":"markdown","source":"We can tell by visual inspection of fake samples that the model didn't reach the quality of the original dataset. However, it managed to learn the basic structure of a chest radiograph (black corners, dark lungs, etc.). It fails to capture the small scale objects such as bones. For this reason and more, more complex models are usually used instead of the `WGAN-GP`. For example, deeper networks would take longer to train but can pick up on more patterns if properly trained. Such models include [StyleGAN](https://arxiv.org/pdf/1812.04948) (and its successors) and [BigGAN](https://arxiv.org/abs/1809.11096).","metadata":{}},{"cell_type":"code","source":"chest_gan.show_fake(\"healthy-4samples.png\", label=[0, 0, 0, 0, 0], num_images=4)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T12:47:28.361238Z","iopub.execute_input":"2022-07-12T12:47:28.361909Z","iopub.status.idle":"2022-07-12T12:47:28.765002Z","shell.execute_reply.started":"2022-07-12T12:47:28.361860Z","shell.execute_reply":"2022-07-12T12:47:28.763464Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"chest_gan.show_fake(\"healthy-20.png\", label=[0, 0, 0, 0, 0], num_images=20)","metadata":{"execution":{"iopub.status.busy":"2022-07-12T12:47:28.768134Z","iopub.execute_input":"2022-07-12T12:47:28.768696Z","iopub.status.idle":"2022-07-12T12:47:31.523780Z","shell.execute_reply.started":"2022-07-12T12:47:28.768633Z","shell.execute_reply":"2022-07-12T12:47:31.522551Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"We want to see how much the GAN managed to capture the label information provided during training.","metadata":{}},{"cell_type":"code","source":"def evaluate(gan, labels_target, labels_target_, num_samples=100):\n        \n        threshold = 0.5\n        \n        for i, label_name in enumerate(labels_target):\n            \n            for target in [0, 1]:\n\n                label = gan.num_labels * [0]\n\n                if target:\n                    label[i] = 1\n                    name = label_name  \n                else:\n                    name = labels_target_[i]  \n                \n                prompt = tf.reshape(tf.cast(label, tf.float32), (1, -1))\n                prompt = tf.expand_dims(tf.expand_dims(prompt, axis=1), axis=2)\n                prompt = tf.tile(prompt, [num_samples, 1, 1 ,1])\n                \n                z = tf.random.normal(shape=(num_samples, 1, 1, gan.latent_dim))\n                gen_in = tf.concat([z, prompt], axis=-1) if gan.num_labels else z\n                fake_images = gan.generator(gen_in)\n                predictions = gan.discriminator(fake_images)\n                proba = tf.math.sigmoid(predictions[:, 1+i])\n                if not target:\n                    proba = 1 - proba\n                compare = tf.cast(proba > threshold, tf.float32)\n                print(f\"Label '{name}' predicted correctly {tf.reduce_mean(compare)*100:.3f}% of the time.\")","metadata":{"execution":{"iopub.status.busy":"2022-07-12T12:47:31.525560Z","iopub.execute_input":"2022-07-12T12:47:31.526068Z","iopub.status.idle":"2022-07-12T12:47:31.540213Z","shell.execute_reply.started":"2022-07-12T12:47:31.526017Z","shell.execute_reply":"2022-07-12T12:47:31.539122Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"evaluate(chest_gan, labels_target, labels_target_, num_samples=1000)","metadata":{"id":"RFlC2ICxE_v9","outputId":"b54ef828-8ff8-4b27-c659-6f3799dac808","execution":{"iopub.status.busy":"2022-07-12T12:47:31.543775Z","iopub.execute_input":"2022-07-12T12:47:31.544573Z","iopub.status.idle":"2022-07-12T12:49:18.672714Z","shell.execute_reply.started":"2022-07-12T12:47:31.544532Z","shell.execute_reply":"2022-07-12T12:49:18.671380Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"Finally, we would like to see the effects of each label on each image.","metadata":{}},{"cell_type":"code","source":"num_images = 4\nz = tf.random.normal(shape=(num_images, 1, 1, chest_gan.latent_dim))\n\ndef reset_values(sliders, b):\n    global z\n    for slider in sliders:\n        slider.value = 0\n    z = tf.random.normal(shape=(num_images, 1, 1, chest_gan.latent_dim))\n\ndef show_label_effect(a, b, c, d, e):\n    chest_gan.show_fake(num_images=num_images, label=[a, b, c, e, d], z=z)\n\nlayout = widgets.Layout(display='flex', flex_flow='column', align_items='center', width='50%')\nslider_a = widgets.FloatSlider(min=0, max=1.0, step=0.1, description='Cardiomegaly:', readout_format='.1f', style = {'description_width': 'initial'})\nslider_b = widgets.FloatSlider(min=0, max=1.0, step=0.1, description='Infiltration:', readout_format='.1f')\nslider_c = widgets.FloatSlider(min=0, max=1.0, step=0.1, description='Effusion:', readout_format='.1f')\nslider_d = widgets.FloatSlider(min=0, max=1.0, step=0.1, description='Male:', readout_format='.1f')\nslider_e = widgets.FloatSlider(min=0, max=1.0, step=0.1, description='AP:', readout_format='.1f')\nsliders_list = [slider_a, slider_b, slider_c, slider_d, slider_e]\nreset_button = widgets.Button(description = \"Reset\")\nreset_button.on_click(partial(reset_values, sliders_list))\n\nout = widgets.interactive_output(show_label_effect, {'a': slider_a, 'b': slider_b, 'c': slider_c, 'd': slider_d, 'e': slider_e})\nwidgets.Box([widgets.VBox([slider_a, slider_b, slider_c, slider_d, slider_e, reset_button], layout=layout), out])","metadata":{"execution":{"iopub.status.busy":"2022-07-12T12:49:18.674471Z","iopub.execute_input":"2022-07-12T12:49:18.675699Z","iopub.status.idle":"2022-07-12T12:49:18.949817Z","shell.execute_reply.started":"2022-07-12T12:49:18.675647Z","shell.execute_reply":"2022-07-12T12:49:18.948550Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"You can see that by increasing the value corresponding to `Cardiomegaly`, the heart is enlarged.","metadata":{}}]}